{
    "format": "CRISP",
    "version": 1,
    "review_id": "ns-nufft-backends-fixes-2025-08-20",
    "summary": "Fix CUFINUFFT Plan() signature clash across versions, map torch dtype to numpy, and make torchkbnufft backend robust to omega/x batch-size mismatch so diag_AHA_scalar probes donâ€™t fail. Only minimal, anchored edits; valid JSON and safe regex.",
    "changes": [
      {
        "target": "graspcg/nufft/backends/cufi.py",
        "actions": [
          {
            "op": "insert_after",
            "match": {
              "type": "literal",
              "pattern": "import torch"
            },
            "content": "\nimport numpy as np\n"
          },
          {
            "op": "insert_after",
            "match": {
              "type": "literal",
              "pattern": "n_trans = C if self.vectorize_coils else 1"
            },
            "content": "\n        # Map torch dtype to numpy dtype expected by cufinufft\n        plan_dtype_np = np.float32 if self.plan_dtype == torch.float32 else np.float64\n"
          },
          {
            "op": "replace",
            "match": {
              "type": "regex",
              "pattern": "plan2\\s*=\\s*_CuFiPlan\\([^\\n]\\)",
              "flags": [
                "MULTILINE"
              ]
            },
            "replacement": "plan2 = _CuFiPlan(\n                2, self.ndim, nmodes=spatial,\n                n_trans=n_trans, eps=self.eps, isign=self.isign,\n                dtype=plan_dtype_np,\n                gpu_device_id=(self._dev.index if (self._dev is not None and self._dev.type == 'cuda') else 0)\n            )"
          },
          {
            "op": "replace",
            "match": {
              "type": "regex",
              "pattern": "plan1\\s=\\s*_CuFiPlan\\([^\\n]\\)",
              "flags": [
                "MULTILINE"
              ]
            },
            "replacement": "plan1 = _CuFiPlan(\n                1, self.ndim, nmodes=spatial,\n                n_trans=n_trans, eps=self.eps, isign=self.isign,\n                dtype=plan_dtype_np,\n                gpu_device_id=(self._dev.index if (self._dev is not None and self._dev.type == 'cuda') else 0)\n            )"
          }
        ],
        "notes": "Use keyword nmodes to avoid positional ambiguity across CUFINUFFT versions and pass numpy dtype. This prevents Plan.__init__() got multiple values for argument 'n_trans'."
      },
      {
        "target": "graspcg/nufft/backends/torchkb.py",
        "actions": [
          {
            "op": "replace",
            "match": {
              "type": "regex",
              "pattern": "om\\s=\\sself\\._traj_BndK\\s\\n\\sy\\s=\\sself\\._fwd\\(x_coils,\\\\som\\\\)",
              "flags": [
                "MULTILINE"
              ]
            },
            "replacement": "om = self._traj_BndK\n        # Allow B mismatch during calibration/probes\n        B_om = int(om.shape[0]) if om.ndim == 3 else 1\n        B_x  = int(x.shape[0])\n        if B_om != B_x:\n            if B_om == 1:\n                om = om.expand(B_x, -1, -1)\n            elif B_x == 1:\n                om = om[:1]\n            else:\n                raise RuntimeError(f\"Omega batch ({B_om}) must match x batch ({B_x}) or be 1.\")\n        y = self._fwd(x_coils, om)"
          },
          {
            "op": "replace",
            "match": {
              "type": "regex",
              "pattern": "om\\s*=\\sself\\._traj_BndK\\s\\n\\sx_c\\s=\\sself\\._adj\\(yw,\\\\som\\\\)",
              "flags": [
                "MULTILINE"
              ]
            },
            "replacement": "om = self._traj_BndK\n        # Allow B mismatch during calibration/probes\n        B_om = int(om.shape[0]) if om.ndim == 3 else 1\n        B_y  = int(y.shape[0])\n        if B_om != B_y:\n            if B_om == 1:\n                om = om.expand(B_y, -1, -1)\n            elif B_y == 1:\n                om = om[:1]\n            else:\n                raise RuntimeError(f\"Omega batch ({B_om}) must match y batch ({B_y}) or be 1.\")\n        x_c = self._adj(yw, om)"
          }
        ],
        "notes": "Make A/AH robust when stored omega has B=1 but probe tensors use B=1 or B>1, fixing the diag_AHA_scalar probe failures without changing the public API or scale_traj."
      }
    ]
  }